[toc]

# 1、集群的简介

## 1.1、集群的基本概念

集群是一组**协同工作**的服务器，**各有分工**，对外表现为**一个整体**。

## 1.2、集群的分类

![sgg-集群分类01]()

![sgg-集群分类02]()

![sgg-集群分类03]()



# 2、负载均衡集群

## 2.1、负载均衡器分类

### 2.1.1、按照软硬件分类

软件：`LVS`，`Nginx`，`HAPROXY`

硬件: `F5`

### 2.1.2、按照工作层级进行分类

​	![ssg-负载均衡集群01]()

&emsp; `F5`工作可以在数据链路层，比如我国的网络是分成移动、电信、网通三家主体的，`F5`的在数据链路层的工作原理就是看来源

是电信还是网通，那么就通过电信专线或者网通的专线转发出去。也就是比如你三家主要网络供应商，都买上一根线。然后`F5`根

据不同的请求源使用不同的线路进行转发出去。`F5`也可以做

&emsp;`LVS`工作在传输层

&emsp;`Nginx`工作在应用层

&emsp;`DNS`可以做到一个域名解析成多个`IP`，不同的`IP`可以解析到一个域名。

## 2.2、负载均衡集群原理

### 2.2.1、 四层工作逻辑
​	![sgg-负载均衡集群原理01]()
&emsp;`LVS`只是改动了一下`IP`地址，根本就没有读取报文的内容，所以这样的设计就能减轻很大的压力，提高性能。我只是进行了一

些地址信息的更改，没有数据转发，没有涉及真实的流量转发和流量生产。这就是`LVS`的性能好的原因。

&emsp;注意`LVS`这张图就好比。一个物流批发站，货物从西安到鹤岗经过这个物流批发站，但是**不会进入**物流批发站，只是在物流批发

站的外面重新的贴了标签，确保货物能准确的送到，所以这整个过程是一个`TCP`连接。

### 2.2.2 、七层工作逻辑

​	![sgg-负载均衡集群原理02]()

&emsp;注意`Nginx`这张图就好比。一个物流批发站，货物从西安到鹤岗经过这个物流批发站，**会进入**物流批发站，所以这就会对我们

的物流站有很大的压力，所以左边客户到`Nginx`是一个`TCP`连接。而右边`Nginx`到真实服务器是另外的一个`TCP`连接。

​	![sgg-负载均衡集群原理03]()

&emsp;所以，`Nginx`的负载均衡能力要比`LVS`差很多。那么为什么我们还要有`Nginx`而不是一直的使用`LVS`。就是因为使用场景的不

同。对于`LVS`我们可以理解，它可以代理`TCP`的，`UDP`，`HTTP`的。所以我们的`Nginx`可以支持`C/S`，`B/S`。但是我们的`Nginx`只

能支持`HTTP`协议（标准版本的`nginx`），那么`Nginx`只能适用于`B/S`。

&emsp;比如有一栋楼，三层住的三哥，二层住的是二哥，一楼有一个门卫大爷。`LVS`的工作原理就是，`A`来找三哥，那么门卫大爷也就

是`LVS`就告诉`A`，三哥在三楼，所以`A`就要自己爬到三楼，然后挨个屋里面寻找三哥。而`Nginx`的原理就是，`Nginx`这个门卫大爷

会自己上到三楼找到三哥，然后带下来给你。直接使用主机名称或者域名，那么使用`Nginx`。有的时候使用主机名或者域名效率

会更高。所以`LVS`只能识别到`TCP`，但是`Nginx`能够识别到协议，主机名，端口和`IP`向下都能看的到。

## 2.3、`LVS`工作模式

​	![sgg-LVS工作模式01]()

&emsp;我们无法直接修改内核配置文件，所以需要一个命令行管理工具进行触发。这个工具就是`ipvsadm`。

![sgg-LVS工作模式02]()

### 2.3.1、`LVS-NAT`工作模式

​	`NAT`读作那它

&emsp;`DNAT`技术就是目标地址转换，目的地址进行更改。

&emsp;`SNAT`技术就是源地址转换，源地址进行更改。

![ssg-lvs-nat工作模式01]()

![ssg-lvs-nat工作模式02]()

&emsp;这样做会出现问题，因为数据包返回的源地址和我发送请求时候的原地址不同，所以要进行源地址转换。所以有下图：

![ssg-lvs-nat工作模式03]()

![ssg-lvs-nat工作模式04]()

### 2.3.2、`LVS-DR`工作模式

&emsp;负载调度器和真实服务器要处于同一个广播域中。

![ssg-lvs-dr工作模式01]()

![ssg-lvs-dr工作模式02]()

![ssg-lvs-dr工作模式03]()

&emsp;从上图可以看到如果这样的进行转发，又发生了`NAT`模型中发生的问题。客户端收到的包数据中的源`IP`发生了变更。所以有了如下的方案：

![ssg-lvs-dr工作模式04]()

&emsp;这样通过上面的方式就解决了这个，客户端收到的包数据中的源`IP`发生了变更的问题。

![ssg-lvs-dr工作模式05]()

&emsp;在`DR`模式下面有一种问题，修改`DMAC`之后，把这个数据包从新发送到广播域中，为了让`RealServer`能接受这个数据包，我们给

&emsp;`RealServer`也配置了`Director`的`IP`，那么如何防止`IP`地址出现问题，给`IP`地址添加了一个`lo:0 10.10.10.100`，为了防

止一个广播域中存在多个同样的`IP`地址，产生冲突，那么就需要对`ARP`进行相应的设置。

&emsp;`arp-ignore`叫做响应级别，也就是我一个数据包到达一个网卡，那么我这个网卡到底是响应，还是不响应，要不要给你回信

息，这个就是`arp-ignore`的设置。比如一台电脑有两个网卡，其中一个是`eth0`对应的`IP`地址是`10.10.10.11`，另外的一个是

`eth1`对应的`IP`地址是`20.20.20.11`。那么当有一个数据包，想找`20.20.20.11`但是它是从`10.10.10.11`进入的。那么如果

`arp-ignore`设置为`0`那么我这个`eth0`网卡也会响应它。如果是设置`arp-ignore`是`1`的话，那么`eth0`就不会进行响应。尽管我

台计算机，有两个网卡`eth0`和`eth1`那么如果设置`arp-ignore`是`1`那么我就不响应，以为它不是我，我也不是它，两个网卡是不

通的。

&emsp;那么`arp-announce`是什么意思那？就是还是我有一台电脑但是这台电脑有两个网卡`eth0`和`eth1`，而且这两个网卡分别连接两

个不同的广播域。那么当这个值设置为`0`的时候，`eth0`在向自己的广播域广播自己的`IP`和`MAC`的时候，同时也会把我这台机器上

的`eth1`的`IP`和`MAC`信息广播到`eth0`所在的广播域。而这个值设置为`2`的时候，那么就不会把`eth1`的`IP`和`MAC`信息广播到`eth0`

所在的广播域中。如果这个值设置为`1`的时候就是尽量避免，但是不保证，介于`0`和`1`之间。

&emsp;所以综上所述，如果我这么设置了,设置`arp-ignore`为`1`,同时设置`arp-announce`为`2`，那么我的`lo`是不是就闭嘴了，既不会

对外公告`IP`和`MAC`信息，也能接受发送给我的信息了。但是这样还有一个问题，就是但是这样还是有一个问题，就是数据报文只

能从`eth0`这种接口进入这台机器，是不能通过`lo:0`这样的接口到达这台机器的，那么怎么办？所以我们需要配置一个路由规则。

加入这条规则是`route add -host 10.10.10.100 dev lo:0 `就是告诉我 ，如果来了一个数据包，是发送给`RealServer`的

`10.10.10.100`这个规则的时候，那么你给`eth0`网卡给我接一下，然后给我`lo:0`。这就好比代取快递。然后数据报文到达了

`lo:0`之后，那么`lo:0`在给请求的客户端发送响应数据报文，这个时候使用的就是`lo:0`的`10.10.10.100`这个`IP`地址。

我们还做了一些优化，就是在我们的负载调度器上，关闭了广播地址的公告功能。还有优化方案就是`lo:0`设置子网掩码是`32`位的

`255`。

 

![sgg-实验03]()

![sgg-实验03]()

![sgg-实验03]()

### 2.3.3、`LVS-TUN`工作模式

![ssg-lvs-tun工作模式01]()

![ssg-lvs-tun工作模式02]()

![ssg-lvs-tun工作模式03]()

![ssg-lvs-tun工作模式04]()

# 3、负载均衡集群实验

![sgg-实验01]()

![sgg-实验02]()

![sgg-实验03]()

## 3.1、`LVS-DR`实验

&emsp;`NetworkManager`：不安全的网络策略会被`NetworkManager`强制关闭。所以我们在做实验之前，一定要先关闭

`NetworkManager`。所以比如我们要配置`lo:0`这种开子接口的方案可以会被`NetworkManager`关闭。

&emsp;`service NetworkManager stop && chkconfig NetworkManager off`   

##  3.2、`LVS-NAT`实验



# 4、负载均衡集群调度算法

## 4.1、调度算法基本分类（通用的调度算法）

固定算法（静态调度算法）：只根据算法本身去调度，**不考虑服务器本身**

动态算法（动态调度算法）：除了考虑算法本身，还要**考虑服务器状态**

```
http 链接，分成两类：
     （1）活动链接
     	  传输数据	
     （2）非活动链接
     	  刚建立握手还没有传输数据
          传输数据完毕还没有来得及断开
在lvs调度算法中，会理解为活动链接的资源消耗是非活动链接的256倍
```

![sgg-LVS-调度算法01]()

```
WLC
	第一台服务器   w=1     	第一台服务器   w=2
	0						0
最开始到达的请求数都是0，那么当一个请求来的时候，根据WLC算法会把这个请求发送给第一台服务器，但是根据上面，我们可以看到其实是第二台服务器更好，因为他的权重是2。所以引入了SED算法
```

![sgg-LVS-调度算法02]()

![sgg-LVS-调度算法03]()

&emsp;前面我们使用`DH`算法，如果请求`1.jpeg`这个文件特别的多，那么就会对第一个`SQUID`造成非常大的压力，所以就有了`LBLV`算

法，也就是如果`SQUID1`扛不住了，那么我就在选择下面的一个`SQUID`，把请求发送给它，也让它开始进行缓存。所以这样就减少

了`SQUID1`的压力。那么可以以此增加`SQUID`的个数。

&emsp;最后还有`LBLCR`算法，这个算法就是让`SQUID`之间能进行缓存的同步。而不必全去后面的`APACHE`请求数据。

## 4.2、`LVS持久连接`（`LVS`特有的调度算法）

```
HTTPS   安全   配置    花钱  
消耗性能甚至有SSL握手设备这种物理设备专门做这件事情。
```

&emsp;为什么要有`LVS`持久连接？

![sgg-LVS-调度算法04]()

&emsp;比如，如上图，当客户端发送一个请求到`LVS`，那么`LVS`把这个请求发送给了第一个`APACHE`，这个当然要建立一个`HTTPS`连

接。然后请求的资源返回给了客户端，下一次同样的一个客户端又发送请求，请求一个`APACHE`上的资源。那么又要重新建立一个

`HTTPS`连接。所以创建`HTTPS`连接过程消耗的资源实在是太多了。我们可以使用`SH`调度算法，但是这样就无法实现`RR`了。那么怎

么解决这个问题？使用`LVS`持久连接！持久化连接和`SH`类似，而且这个算法优先于通用算法。我们应该先匹配到持久化连接，然

后再去匹配通用算法。那么我就可以先配置持久化连接，然后再开启`RR`调度算法。那么这样就是既开启了持久化连接，又`RR`也能

轮询了。持久化连接会被普遍应用到我们的`HTTPS`集群中。原理就是在内存分页中采用一块缓存，记录我们的客户端数据与我们

分配的真实服务器的相关数据，保证我们能够在一定时间中持久化。持久化连接的时间会一点一点减少，当持久化连接时间到达`0`

时候，就采用通用算法，比如`RR`进行处理。当我们的持久化时间减少的时候，如果客户端又有请求来了。那么我就把这个持久化

时间，加上`30S`，直到这个时间减为`0`。记住两点：（1）优先级高于通用算法（2）类似于`SH`算法（3）应用于`HTTPS`场景。

![sgg-LVS-调度算法05]()

![sgg-LVS-调度算法06]()

```
集群不先进行处理，而是先打上一个标记，然后根据标记进行处理。这样会更加的灵活，这个要和iptables一起使用。
```



## 5、高可用集群

## 5.1、高可用集群的说明

```
高可用：尽可能的提高服务的可用性
	99  基础
	999 一般要做到，原因是可用性越高，资金成本越高。
	9999 需要硬件设备支持
	99999 理论上的概念
	
	实现原理：心跳检测
	
服务：
	有状态(在N断时间之后，把它添加上，在功能上没有区别，因为数据库中的数据可能已经差很多了)
		MYSQL 	
	无状态(在N断时间之后，把它添加上，在功能上没有任何的区别)
		Apache
		LVS
所以无状态服务好实现高可用，而有状态的不好实现高可用，但是也可以实现。

ifconfig eth0:0 10.10.10.100 netmask 255.255.255.0
```

![sgg-LVS-调度算法06]()

### 问题1、上面的图如果后面的`apache`服务器挂了会发生什么？

```shell
# 脚本的思想：循环判断我们拥有的真实服务器的节点，它的状态是否正常。如果正常，那么静默，等待下次循环。如果不正常，那么添加或者删除。这个脚本在负载均衡器节点执行。

#!/bin/bash
#=============================================================================
VIP=10.10.10.100      #集群虚拟IP
CPORT=80        #定义集群端口
FAIL_BACK=127.0.0.1     #本机回环地址
RS=("10.10.10.12" "10.10.10.13")  #编写集群地址
declare -a RSSTATUS       #变量RSSTATUS定义为数组态
RW=("2" "1")
RPORT=80        #定义集群端口
TYPE=g          #制定LVS工作模式：g=DR m=NAT
CHKLOOP=3
LOG=/var/log/ipvsmonitor.log

#=============================================================================

addrs() {
  ipvsadm -a -t $VIP:$CPORT -r $1:$RPORT -$TYPE -w $2
  [ $? -eq 0 ] && return 0 || return 1
}

delrs() {
  ipvsadm -d -t $VIP:$CPORT -r $1:$RPORT
  [ $? -eq 0 ] && return 0 || return 1
}

checkrs() {
  local I=1
  
  while [ $I -le $CHKLOOP ]
  do
    if curl --connect-timeout 1 http://$1 &> /dev/null
    then
      return 0
    fi
    
    let I++
  done
  
  return 1
}

initstatus() {
  
  local I
  local COUNT=0;

  for I in ${RS[*]}
  do
    if ipvsadm -L -n | grep "$I:$RPORT" && > /dev/null
    then
    
      
      RSSTATUS[$COUNT]=1
    else
      RSSTATUS[$COUNT]=0
    fi
      let COUNT++
  done
}

#=============================================================================
initstatus

while :; do

  let COUNT=0
  for I in ${RS[*]}
  do
    if checkrs $I
    then
      if [ ${RSSTATUS[$COUNT]} -eq 0 ]
      then
                    addrs $I ${RW[$COUNT]}
                  [ $? -eq 0 ] && RSSTATUS[$COUNT]=1 && echo "`date +'%F %H:%M:%S'`, $I is back." >> $LOG
      fi
    else
                  if [ ${RSSTATUS[$COUNT]} -eq 1 ]
      then
                    delrs $I
                    [ $? -eq 0 ] && RSSTATUS[$COUNT]=0 && echo "`date +'%F %H:%M:%S'`, $I is gone." >> $LOG
      fi
    fi
    
    let COUNT++
  done
  sleep 5
done
```

### 问题2、上面解决了真实服务器挂掉的问题，那么如果我们的`LVS`挂了怎么办？

所以我们需要对`LVS`实现高可用，那么我们使用的就是`keepalived`



## 5.2、`Keepalived原理`

![]()









&emsp

# 参考

- [LVS健康检查脚本](https://www.cnblogs.com/lyshark/p/10222252.html)
- 





























